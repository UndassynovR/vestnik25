\id{ГРНТИ 28.23.39}{https://doi.org/10.58805/kazutb.v.4.25-646}

\begin{articleheader}
\sectionwithauthors{V. Ramazanova, M. Sambetbayeva, A. Tokhmetov, Zh. Lamasheva, S. Serikbayeva}{APPLICATION OF AGGLOMERATIVE CLUSTERING FOR FORMING SKILL
COMMUNITIES OF JOB VACANCIES}

{\bfseries V. Ramazanova, M.Sambetbayeva, A}.{\bfseries Tokhmetov, Zh.
Lamasheva, S.Serikbayeva\textsuperscript{\envelope },}
\end{articleheader}

\begin{affiliation}
\textsuperscript{1}L. N. Gumilyov Eurasian National University, Astana,
Kazakhstan,

\raggedright {\bfseries \textsuperscript{\envelope }}Correspondent-author: \href{mailto:inf_8585@mail.ru}{\nolinkurl{inf\_8585@mail.ru}}
\end{affiliation}

One of the traditional methods for community detection in knowledge
graphs is agglomerative clustering. Agglomerative hierarchical
clustering is a widely used type of hierarchical clustering for grouping
objects based on their similarity. This method follows a bottom-up
approach, beginning with each individual data point considered as an
independent cluster, which are then continuously merged based on a
similarity threshold between clusters. This paper focuses on the use of
agglomerative clustering for analyzing skills extracted from job
postings on an online recruitment platform. It describes the approach to
data collection, processing, and subsequent clustering, providing an
overview of linkage methods between clusters and examples of the
application of various coefficients for quantitative assessment of
cluster quality. An analysis of bilingual clusters in Russian and
English is conducted, al-lowing for an evaluation of the versatility and
adaptability of the proposed approach to analyzing the multilingual
labor market in Kazakhstan. It was found that agglomerative clustering
methods hold significant potential for identi-fying structured groups of
skills, which can enhance the understanding of labor market trends and
needs. The analysis of clusters formed in different languages confirmed
the universality and adaptability of the proposed ap-proach to
multilingual data.

{\bfseries Keywords:} Sentence transformers, skills clustering,
agglomerative clustering, silhouette coefficient, skills communities.

\begin{articleheader}
{\bfseries ПРИМЕНЕНИЕ АГЛОМЕРАТИВНОЙ КЛАСТЕРИЗАЦИИ ДЛЯ ФОРМИРОВАНИЯ
СООБЩЕСТВ НАВЫКОВ ВАКАНСИЙ}

{\bfseries В.С.Рамазанова, М.А.Самбетбаева, А.Т. Тохметов, Ж.Б. Ламашева,
С.К.Серикбаева\textsuperscript{\envelope },}
\end{articleheader}

\begin{affiliation}
\textsuperscript{1}Евразийский национальный университет им. Л. Н.
Гумилева, Астана, Казахстан,

e-mail:inf\_8585@mail.ru
\end{affiliation}

Одним из традиционных методов обнаружения сообществ в графах знаний
является агломеративная кластеризация. Агломеративная иерархическая
кластеризация -- это широко используемый тип иерархической кластеризации
для группировки объектов на основе их сходства. Этот метод следует
подходу «снизу-вверх», начиная с того, что каждая отдельная точка данных
рассматривается как независимый кластер, которые затем непрерывно
объединяются на основе порога сходства между кластерами. В данной статье
основное внимание уделяется использованию агломеративной кластеризации
для анализа навыков, извлеченных из объявлений о вакансиях на
онлайн-платформе по подбору персонала. В ней описывается подход к сбору,
обработке и последующей кластеризации данных, дается обзор методов связи
между кластерами и примеры применения различных коэффициентов для
количественной оценки качества кластера. Проводится анализ двуязычных
кластеров на русском и английском языках, что позволяет оценить
универсальность и адаптивность предлагаемого подхода к анализу
многоязычного рынка труда в Казахстане. Было обнаружено, что методы
агломеративной кластеризации обладают значительным потенциалом для
выявления структурированных групп навыков, которые могут улучшить
понимание тенденций и потребностей рынка труда. Анализ кластеров,
сформированных на разных языках, подтвердил универсальность и
адаптивность предлагаемого подхода к многоязычным данным.

{\bfseries Ключевые слова:} Трансформеры предложений, кластеризация
навыков, агломеративная кластеризация, коэффициент силуэта, сообщества
навыков.

\begin{articleheader}
{\bfseries ЖҰМЫС ДАҒДЫЛАРЫ ҚАУЫМДАСТЫҒЫН ҚАЛЫПТАСТЫРУ ҮШІН АГЛОМЕРАТИВТІ
КЛАСТЕРЛЕУДІ ҚОЛДАНУ}

{\bfseries В.С.Рамазанова, М.А.Самбетбаева, А.Т.Тохметов, Ж.Б. Ламашева,
С.К.Серикбаева\textsuperscript{\envelope },}
\end{articleheader}

\begin{affiliation}
\textsuperscript{1}Л.Н.Гумилев атындағы Еуразия ұлттық университеті,
Астана, Қазақстан,

e-mail: inf\_8585@mail.ru
\end{affiliation}

Білім графтарында қауымдастықты анықтаудың дәстүрлі әдістерінің бірі
агломеративті кластерлеу болып табылады. Агломеративті иерархиялық
кластерлеу объектілерді ұқсастығына қарай топтастыру үшін иерархиялық
кластерлеудің кеңінен қолданылатын түрі болып табылады. Бұл әдіс әрбір
жеке деректер нүктесін тәуелсіз кластер ретінде өңдеуден бастап,
төменнен жоғарыға қарай әрекет етеді, содан кейін олар кластерлер
арасындағы ұқсастық шегіне негізделген үздіксіз біріктіріледі. Бұл жұмыс
онлайн жалдау платформасында жұмыс туралы хабарландырулардан алынған
дағдыларды талдау үшін агломеративті кластерлеуді пайдалануға
бағытталған. Ол деректерді жинау, өңдеу және кейіннен кластерлеу тәсілін
сипаттайды, кластерлер арасындағы байланыс әдістеріне шолу жасайды және
кластердің сапасын сандық бағалау үшін әртүрлі коэффициенттерді қолдану
мысалдарын береді. Орыс және ағылшын тілдеріндегі қостілді кластерлерге
талдау жүргізілді, бұл Қазақстанның көптілді еңбек нарығын талдауға
ұсынылып отырған тәсілдің әмбебаптығы мен бейімділігін бағалауға
мүмкіндік береді. Агломеративті кластерлеу әдістері еңбек нарығының
тенденциялары мен қажеттіліктерін түсінуді жақсартатын құрылымдық
дағдылар топтарын анықтау үшін маңызды әлеуетке ие екендігі анықталды.
Әртүрлі тілдерде қалыптасқан кластерлерді талдау көптілді деректерге
ұсынылған тәсілдің әмбебаптығы мен бейімделгіштігін растады.

{\bfseries Түйін сөздер:} Сөйлем трансформерлері, дағдыларды кластерлеу,
агломеративті кластерлеу, силуэт коэффициенті, дағдылар қауымдастықтары.

\begin{multicols}{2}
{\bfseries Introduction.} The rapid growth in the volume of data on skills
and qualifications available through online employment platforms
represents a rich source of information on current and future labor
market trends. However, due to their volume and diversity, clustering
methods play a crucial role in structuring this information. In the
context of graphs, communities, also known as clusters or modules, are
groups of vertices that typically share common characteristics and/or
perform similar functions within the graph {[}1{]}.

One of the methods for community detection in graphs is hierarchical
clustering. Applying agglomerative clustering methods to skills can
reveal not only existing groups of similar skills but also uncover
communities within knowledge graphs. Understanding and analyzing the
structures of skill communities can significantly enhance career
development strategies by fostering closer integration between
educational and professional training and market needs.

The goal of this work is to create clusters that group semantically
similar skills, which, though they may be phrased differently, retain
the same overall meaning. The results of such clustering are intended to
form communities of nodes in knowledge graphs, allowing for a deeper
exploration of skill structures in the market.

This paper focuses on the use of agglomerative clustering for analyzing
skills extracted from job postings on the online recruitment platform
HeadHunter in Kazakhstan. It describes the approach to data collection,
processing, and subsequent clustering, providing an overview of
methodologies and examples of applying various metrics to assess cluster
quality. An analysis and comparison of clusters obtained with different
agglomerative clustering parameters for sets of phrases in Russian and
English were conducted, allowing for an evaluation of the versatility
and adaptability of the proposed approach to analyzing the modern labor
market.

{\bfseries Literature review.} Hierarchical clustering is highlighted as
one of the traditional methods for community detection in graph
structures in article {[}1{]}. Hierarchical clustering is widely used in
various fields such as social networks and biology. This method begins
with defining a measure of similarity between all pairs of vertices.
Agglomerative algorithms, which merge clusters based on similarity, do
not require a pre-specified number of clusters, which is an advantage.
However, the main drawback of agglomerative hierarchical clustering is
poor scalability.

Articles {[}2{]} and {[}3{]} provide a detailed overview of various
agglomerative hierarchical clustering methods, such as single linkage,
complete linkage, average linkage, and Ward' s method.
These methods are used to group objects based on their similarity, which
is applicable to the analysis of skills from job postings. As noted in
{[}3{]}, the choice of metric and linkage method significantly impacts
clustering results, necessitating a careful approach to parameter
tuning. This is particularly important for text data analysis, where
selecting an appropriate metric can substantially affect the quality of
clusters and, consequently, skill analysis. The algorithm proposed in
article {[}4{]} presents a distributed approach to agglomerative
clustering that can be efficiently scaled to handle billions of objects.
Article {[}5{]} introduces the concept of using the Ordered Weighted
Averaging (OWA) operator to modify traditional linkages in agglomerative
hierarchical clustering. This method is of interest for research aimed
at enhancing the flexibility and robustness of clustering algorithms.

The use of the silhouette coefficient to evaluate cluster quality, as
demonstrated in {[}6{]}, allows for assessing the degree of separation
of clusters and determining the optimal number of clusters. On the other
hand, studies {[}7{]} highlight the limitations of the silhouette
coefficient and the Calinski-Harabasz index, which can lead to
misinterpretation of clustering results. In such cases, an additional
expert review of the data may be helpful to improve understanding of the
internal structure of the clusters.

Article {[}8{]} describes in detail how proper text preprocessing, such
as sentence segmentation, tokenization, stop-word removal, and
lemmatization, can significantly improve the quality and accuracy of
machine learning algorithms. The study {[}9{]} examines sentence vector
representations based on Transformer models in combination with various
clustering methods. Article {[}10{]} discusses the semantic accuracy of
models. The authors compare four freely available pre-trained sentence
transformer models (all-MiniLM-L6-v2, all-MiniLM-L12-v2,
all-mpnet-base-v2, and all-distilroberta-v1) on a sample of 6,110
articles and select the most efficient model, all-mpnet-base-v2.

Article {[}11{]} addresses the complex task of clustering categorical
data in data analysis. The author proposes an algorithm for clustering
job vacancies based on required skills using hierarchical clustering and
the Girvan-Newman method to identify job clusters. Article {[}12{]}
explores the use of two popular data clustering methods: K-Means and
agglomerative clustering, on data related to seafarer certification
skills. The authors analyze the advantages of each approach, including
K-Means ability to quickly process large volumes of data and provide
clearly delineated clusters, while agglomerative clustering offers a
detailed, hierarchical view of the data, useful for understanding
complex structures of certification requirements. The study {[}13{]}
analyzes the performance of text data clustering using the TF-IDF
method, fuzzy K-means, and hierarchical agglomerative clustering on
datasets such as News 20, Reuters, and email collections. The results
show that hierarchical agglomerative clustering provides better
performance compared to fuzzy K-means, including lower entropy and
higher F-measure values, indicating clearer separation and consistency
of clusters.

Article {[}14{]} describes the use of the Hierarchical Dirichlet Process
(HDP) for clustering documents that define skills in an industrial
environment for large IT companies. The article {[}15{]} studies
thematic clustering using TF-IDF and K-Means methods in the field of
information technology. The articles {[}16-17{]} consider clustering of
vacancies based on skills.

Thus, the literature review emphasizes the importance of selecting the
appropriate clustering methods and metrics in data analysis. Studies
show that hierarchical agglomerative clustering offers its advantages
depending on data characteristics and analysis goals. Clustering
efficiency increases with the use of adapted metrics and methods, which
is crucial for achieving accuracy and validity of results. The
implementation of innovative approaches enhances the flexibility and
scalability of methods, which is critically important when working with
large volumes of data. Assessing cluster quality through silhouette
coefficients and other indices helps determine the optimal number of
clusters, ensuring clearer data separation and consistency.

{\bfseries Materials and methods.} \emph{Collection, processing and
preparation of data embeddings.}

The dataset on skills was downloaded from the online recruitment site
hh.kz in Russian and English using the provided API
(https://api.hh.ru/vacancies) and the Python programming language.
Skills from job vacancies were collected over two months, from February
1, 2024, to March 31, 2024, from 177 localities in Kazakhstan, covering
25 professions in the information technology sector: analyst, art
director, creative director, game designer, designer, artist, chief
information officer (CIO), product manager, programmer, developer,
development team lead, project manager, network engineer, system
administrator, system engineer, information security specialist,
technical support specialist, tester, chief technology officer (CTO),
technical writer, system analyst, business analyst, methodologist, BI
analyst, data analyst, head of analytics department, DevOps engineer,
product analyst, and data scientist. The number of vacancies amounted to
5248. The number of unique skills totaled 3047.Skill phrases were
treated as sentences.

Next, from the data set of vacancies and skills, a knowledge graph was
built in the neo4j graph DBMS. Let' s consider the
ontological model of the graph of skills and vacancies. The graph
includes a set of entity classes: E\textsubscript{Recruitment} =
\{Vacancy, Skill, Requirement, Responsibility\} and a set of
relationships: R\textsubscript{Recruitment} = \{REQUIRE,
HAS\_REQUIREMENT, HAS\_RESPONSIBILITY\}.
\end{multicols}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{media/ict/image104}
	\caption*{Fig. 1 - Example of a subgraph of vacancies and skills. The
node representing the vacancy is marked in purple, skill nodes are
marked in red, requirement nodes are marked in blue, and responsibility
nodes are marked in yellow}
\end{figure}

\begin{multicols}{2}
Figure 1 presents a subgraph centered on the node representing the
vacancy "Senior IT Project Specialist (Aksai)" and other related skills
and vacancies. This node is connected to other nodes representing
skills, requirements, and responsibilities that describe various aspects
of its role and qualifications.

A notable feature of this graph is the presence of many paraphrased
skills that share the same meaning. Subsequently, it is necessary to
construct communities of semantically similar paraphrased skills for the
job vacancy skills graph.

Duplicates were removed from the set of skill phrases, all skills were
converted to lower case, and phrase embeddings were generated using the
paraphrase-multilingual-mpnet-base-v2 model.
Paraphrase-multilingual-mpnet-base-v2 is a pre-trained transformer model
designed to generate text embeddings, mapping sentences and paragraphs
into a 768-dimensional dense vector space. The model is trained on over
fifty languages and optimized to create vectors that effectively
represent the semantic content of text, making the embeddings
particularly useful for tasks related to paraphrase identification,
semantic search, and text clustering. The embeddings generated by this
model capture the semantic and contextual features of the text, making
them suitable for grouping texts by meaning.

\emph{Selection of clustering method, visualization and evaluation}.
Agglomerative clustering is a type of hierarchical clustering used to
group objects into clusters based on their similarity. It is considered
a "bottom-up" method because it starts with each object initially
considered as a separate cluster, and then, step by step, clusters are
merged until a specified number of clusters or a distance threshold is
reached (Fortunato, 2010).

The configuration for agglomerative clustering involves several
parameters: n\_clusters - the number of clusters to find, should be None
if distance\_threshold is specified; distance\_threshold - this
parameter sets the distance threshold to stop clustering; metric - a
``cosine'' or ``Euclidean'' metric was used to measure the distance
between clusters, if the relationship is ``ward'', only the "Euclidean"
metric is accepted; linkage - the link criterion determines what
distance to use between sets of observations. The algorithm will combine
pairs of clusters that minimize this criterion: ``ward'' minimizes the
variance of the clusters being merged, ``average'' uses the average of
the distances of each observation of two sets, ``full'' or ``maximum''
link uses the maximum distances between all observations of two sets,
``single'' uses the minimum distance between all observations of two
sets.

The visualization of the results was performed using the scikit-learn
and matplotlib libraries and the t-SNE (t-distributed Stochastic
Neighbor Embedding) dimensionality reduction technique (Scikit-learn
user guide, n.d.). The main advantage of t-SNE is its ability to
preserve local data structures, which makes it possible to identify
clusters and groups that may be hidden in high-dimensional data.

If the true cluster labels are unknown, clustering evaluation must be
performed using the model itself. The silhouette coefficient is an
example of such a score, where a higher silhouette coefficient score
refers to a model with more clearly defined clusters. Silhouette
coefficient is a metric that measures how well each data point fits into
its assigned cluster. It combines information about both the
connectivity (how close data point \emph{a} is to other points in its
own cluster) and separation (how far data point b is from points in
other clusters) of the data point technique (Scikit-learn user guide,
n.d.).

The Calinski-Harabasz index, also known as the Variance Ratio Criterion,
can also be used to evaluate the model, where a higher Calinski-Harabasz
score corresponds to a model with well-defined clusters. The score is
higher when clusters are dense and well-separated, which aligns with the
standard concept of a cluster technique (Scikit-learn user guide, n.d.).

Our approach to determining the optimal silhouette coefficient is based
on an iterative experimental programmatic process in which the distance
threshold between clusters was cyclically set for different proximity
metrics and linkage types to determine the maximum value of the
silhouette coefficient. Ranges of the «Distance\_threshold» parameter
were tested to determine the point at which a balance among the average
silhouette coefficient (should be maximum), the percentage of clusters
with negative silhouette coefficient (should be closer to zero), and
visual inspection of the clusters was observed. The program for the
cyclic process was implemented in Python using the Scikit-learn library.

{\bfseries Results and discussions.} As a result of the experiments, 3047
skill phrases were processed. Table 1 presents data on various metrics
(cosine, euclidean), linkage types (average, complete, single, ward),
distance threshold values, the number of clusters, the average
silhouette coefficient of all clusters, the percentage of clusters with
a silhouette coefficient above 0.03 (the most successful clusters), the
percentage of clusters with a negative silhouette coefficient, and the
average Calinski-Harabasz index.

The data for Table 1, starting from the fourth column, were obtained as
a result of cyclic operation of the agglomerative clustering algorithm
for three initial parameters (the first three columns), with
programmatically evaluation of cluster quality by silhouette and
Calinski-Harabasz coefficient algorithms.
\end{multicols}
\small{
\begin{longtable}[c]{|llllllll|}
\caption*{Table 1 - Parameters and results of experiments} \\
\hline
\multicolumn{3}{|l|}{\textbf{Clustering parameters}} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
   \\ \cline{1-3}
\multicolumn{1}{|l|}{\textbf{Metric}} &
  \multicolumn{1}{l|}{\textbf{Linkage}} &
  \multicolumn{1}{l|}{\textbf{\begin{tabular}[c]{@{}l@{}}Distance\_\\  threshold\end{tabular}}} &
  \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Number \\ of \\ clusters\end{tabular}}}} &
  \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Average \\ silhouette c\\ oefficient of \\ all clusters\end{tabular}}}} &
  \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Percentage of\\  clusters with \\ silhouette \\ coefficient \\ greater than \\ 0.03\end{tabular}}}} &
  \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Percentage of \\ clusters with \\ negative \\ silhouette \\ coefficient\end{tabular}}}} &
  \multirow{-2}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Average \\ Calinski-\\Harabasz \\ index\end{tabular}}} \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} & \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} & \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} & \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} & \\ \hline
\endfirsthead
%
\endhead
%
%
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.2} &
  \multicolumn{1}{l|}{1669} &
  \multicolumn{1}{l|}{0.25506} &
  \multicolumn{1}{l|}{33.97\%} &
  \multicolumn{1}{l|}{0\%} &
  9.60789 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.24} &
  \multicolumn{1}{l|}{1403} &
  \multicolumn{1}{l|}{0.26764} &
  \multicolumn{1}{l|}{40.77\%} &
  \multicolumn{1}{l|}{0.07\%} &
  9.03752 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.25} &
  \multicolumn{1}{l|}{1335} &
  \multicolumn{1}{l|}{0.27106} &
  \multicolumn{1}{l|}{42.77\%} &
  \multicolumn{1}{l|}{0.07\%} &
  9.03694 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.26} &
  \multicolumn{1}{l|}{1280} &
  \multicolumn{1}{l|}{0.26711} &
  \multicolumn{1}{l|}{43.44\%} &
  \multicolumn{1}{l|}{0.07\%} &
  8.88383 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.27} &
  \multicolumn{1}{l|}{1221} &
  \multicolumn{1}{l|}{0.26728} &
  \multicolumn{1}{l|}{44.31\%} &
  \multicolumn{1}{l|}{0\%} &
  8.83944 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.28} &
  \multicolumn{1}{l|}{1166} &
  \multicolumn{1}{l|}{0.27018} &
  \multicolumn{1}{l|}{46.14\%} &
  \multicolumn{1}{l|}{0\%} &
  8.77975 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.29} &
  \multicolumn{1}{l|}{1121} &
  \multicolumn{1}{l|}{0.27126} &
  \multicolumn{1}{l|}{47.55\%} &
  \multicolumn{1}{l|}{0\%} &
  8.76839 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.3} &
  \multicolumn{1}{l|}{1077} &
  \multicolumn{1}{l|}{0.27041} &
  \multicolumn{1}{l|}{48.75\%} &
  \multicolumn{1}{l|}{0.09\%} &
  8.76821 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.31} &
  \multicolumn{1}{l|}{1023} &
  \multicolumn{1}{l|}{0.26873} &
  \multicolumn{1}{l|}{49.76\%} &
  \multicolumn{1}{l|}{0.09\%} &
  8.74085 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.32} &
  \multicolumn{1}{l|}{978} &
  \multicolumn{1}{l|}{0.26798} &
  \multicolumn{1}{l|}{51.43\%} &
  \multicolumn{1}{l|}{0.1\%} &
  8.77425 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.4} &
  \multicolumn{1}{l|}{636} &
  \multicolumn{1}{l|}{0.23460} &
  \multicolumn{1}{l|}{61.16\%} &
  \multicolumn{1}{l|}{0.31\%} &
  8.96599 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{\multirow{-12}{*}{average}} &
  \multicolumn{1}{l|}{0.5} &
  \multicolumn{1}{l|}{357} &
  \multicolumn{1}{l|}{0.17152} &
  \multicolumn{1}{l|}{72.55\%} &
  \multicolumn{1}{l|}{0.84\%} &
  9.38007 \\ \cline{2-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.29} &
  \multicolumn{1}{l|}{1342} &
  \multicolumn{1}{l|}{0.28119} &
  \multicolumn{1}{l|}{{\color[HTML]{212121} 49.93\%}} &
  \multicolumn{1}{l|}{2.6\%} &
  9.45677 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.3} &
  \multicolumn{1}{l|}{1295} &
  \multicolumn{1}{l|}{0.28338} &
  \multicolumn{1}{l|}{51.43\%} &
  \multicolumn{1}{l|}{2.78\%} &
  9.48204 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.31} &
  \multicolumn{1}{l|}{1257} &
  \multicolumn{1}{l|}{0.28413} &
  \multicolumn{1}{l|}{52.51\%} &
  \multicolumn{1}{l|}{2.86\%} &
  9.43280 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.32} &
  \multicolumn{1}{l|}{1222} &
  \multicolumn{1}{l|}{0.28468} &
  \multicolumn{1}{l|}{53.68\%} &
  \multicolumn{1}{l|}{2.86\%} &
  9.43222 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.33} &
  \multicolumn{1}{l|}{1175} &
  \multicolumn{1}{l|}{0.28383} &
  \multicolumn{1}{l|}{55.15\%} &
  \multicolumn{1}{l|}{2.89\%} &
  9.33287 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.34} &
  \multicolumn{1}{l|}{1143} &
  \multicolumn{1}{l|}{0.28272} &
  \multicolumn{1}{l|}{55.47\%} &
  \multicolumn{1}{l|}{3.32\%} &
  9.31358 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.35} &
  \multicolumn{1}{l|}{1099} &
  \multicolumn{1}{l|}{0.28272} &
  \multicolumn{1}{l|}{57.23\%} &
  \multicolumn{1}{l|}{3.37\%} &
  9.30610 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{\multirow{-8}{*}{complete}} &
  \multicolumn{1}{l|}{0.4} &
  \multicolumn{1}{l|}{916} &
  \multicolumn{1}{l|}{0.27294} &
  \multicolumn{1}{l|}{63.54\%} &
  \multicolumn{1}{l|}{3 .93\%} &
  9.39409 \\ \cline{2-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.2} &
  \multicolumn{1}{l|}{1045} &
  \multicolumn{1}{l|}{-0.18031} &
  \multicolumn{1}{l|}{19.14\%} &
  \multicolumn{1}{l|}{0.27\%} &
  2.39889 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{0.29} &
  \multicolumn{1}{l|}{406} &
  \multicolumn{1}{l|}{-0.28775} &
  \multicolumn{1}{l|}{{\color[HTML]{212121} 17.24\%}} &
  \multicolumn{1}{l|}{0.49\%} &
  1.84882 \\ \cline{3-8} 
\multicolumn{1}{|l|}{\multirow{-23}{*}{cosine}} &
  \multicolumn{1}{l|}{\multirow{-3}{*}{single}} &
  \multicolumn{1}{l|}{0.39} &
  \multicolumn{1}{l|}{106} &
  \multicolumn{1}{l|}{-0.19031} &
  \multicolumn{1}{l|}{17.92\%} &
  \multicolumn{1}{l|}{0.94\%} &
  1.89379 \\ \hline
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{2} &
  \multicolumn{1}{l|}{1316} &
  \multicolumn{1}{l|}{0.25526} &
  \multicolumn{1}{l|}{47.72\%} &
  \multicolumn{1}{l|}{4.79\%} &
  10.69402 \\ \cline{3-8} 
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{2.5} &
  \multicolumn{1}{l|}{894} &
  \multicolumn{1}{l|}{0.26155} &
  \multicolumn{1}{l|}{62.08\%} &
  \multicolumn{1}{l|}{7.49\%} &
  10.48007 \\ \cline{3-8} 
\multicolumn{1}{|l|}{\multirow{-3}{*}{euclidean}} &
  \multicolumn{1}{l|}{\multirow{-3}{*}{ward}} &
  \multicolumn{1}{l|}{2.9} &
  \multicolumn{1}{l|}{666} &
  \multicolumn{1}{l|}{0.24942} &
  \multicolumn{1}{l|}{{\color[HTML]{212121} 72.67\%}} &
  \multicolumn{1}{l|}{9.46\%} &
  10.89370 \\ \hline
\multicolumn{8}{|l|}{\textbf{Note - Compiled by the author}} \\ \hline
\end{longtable}}

\begin{multicols}{2}
When using cosine similarity with average linkage, a significant
reduction in the number of clusters from 1669 to 357 is observed as the
distance threshold increases from 0.2 to 0.5. In this parameter
configuration, the silhouette coefficient is of primary interest, and
the optimal threshold for balanced clustering is found to be between
0.28 and 0.3, where good silhouette scores are achieved while
maintaining a reasonable number of clusters.

For cosine similarity with complete linkage, the silhouette coefficient
varies from 0.28119 to 0.27294. The complete linkage method exhibits a
significant increase in the percentage of negative silhouettes (up to
3.93\% at a threshold of 0.4), which may be attributed to its tendency
to form clusters by combining distantly located elements, thereby
increasing group overlap.

When using cosine similarity with single linkage, poor clustering
quality is evident, with negative average silhouette values and low
Calinski-Harabasz index scores, indicating an unsuitable linkage method
for this type of data. The method exhibits negative average silhouette
values, indicating extremely weak separation between clusters.

For Euclidean similarity with Ward linkage, a threshold of 2.5 is
optimal in terms of the silhouette coefficient, providing a good balance
between the number and quality of clusters. The method shows an increase
in the percentage of negative silhouettes as the threshold increases,
reaching 9.46\% at a threshold of 2.9, indicating that as the threshold
increases, cluster quality deteriorates, and clusters become more
diffuse and overlapping.

The average and complete methods with cosine similarity generally yield
better silhouette coefficient results, particularly at intermediate
threshold values, allowing for a balance between the number of clusters
and their quality. The percentage of negative silhouette coefficients
indicates the degree of overlap or misclassification within groups,
serving as a crucial indicator of cluster structure quality. Further
examination of the data leads to the selection of cosine similarity with
average linkage and a distance threshold of 0.29, as this option
demonstrates the best silhouette coefficient results.

Figure 2 depicts the distribution of skill clusters using average
linkage with cosine similarity at a distance threshold of 0.29, where
each point represents a specific skill, and the color indicates
membership in one of the clusters.
\end{multicols}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{media/ict/image105}
	\caption*{Fig. 2 - Distribution of skill clusters using average linkage
with cosine similarity at a distance threshold of 0.29}
\end{figure}

\begin{multicols}{2}
The points are evenly distributed across the graph, although there is
some concentration in the center. This may indicate common or frequently
occurring skills that do not exhibit distinct unique properties, in
contrast to rarer or more specialized skills found on the periphery.

Grouped points represent niche skills that are divided into several
clusters. For instance, Table 2 shows several clusters related to
testing. As described in the Materials and methods section, the
clustering data was collected in Russian and English. In this case, the
phrases in the data could be completely in the same language or contain
elements of both languages at the same time.

The list of clusters containing both Russian and English terms
highlights the bilingual nature of the data. Including skills in both
languages can enhance the understanding of professional competency
requirements across different regions, thereby increasing the
universality of research in employment and education.

Some clusters overlap with each other, which may result from fuzzy
boundaries between skills or the proximity of their content. Cluster 33
is the last cluster with a silhouette coefficient greater than zero.
Table 3 shows cluster 33, which includes many unrelated abbreviations
and monosyllabic terms.
\end{multicols}

\begin{table}[H]
\caption*{Table 2 - Example of clusters}
\centering
\begin{tabular}{|llp{0.13\textwidth}|}
\hline
\multicolumn{1}{|c|}{\textbf{Cluster number}} &
  \multicolumn{1}{c|}{\textbf{Skills in the cluster}} &
  \textbf{Silhouette coefficient} \\ \hline
\multicolumn{1}{|l|}{248} &
  \multicolumn{1}{p{0.6\textwidth}|}{тестирование мобильного приложения, тестирование мобильных приложений, диагностика смартфонов} &
  0.53794 \\ \hline
\multicolumn{1}{|l|}{130} &
  \multicolumn{1}{p{0.6\textwidth}|}{автоматизированное тестирование, автотестирование, автоматизация тестирования, automation test, auto-testing} &
  0.5163 \\ \hline
\multicolumn{1}{|l|}{214} &
  \multicolumn{1}{p{0.6\textwidth}|}{тестирование пользовательского интерфейса, тестирование новых девайсов} &
  0.18981 \\ \hline
\multicolumn{1}{|l|}{478} &
  \multicolumn{1}{p{0.6\textwidth}|}{проведение ux/ui тестирований, unit testing, ui test} &
  0.1366 \\ \hline
\multicolumn{1}{|l|}{116} &
  \multicolumn{1}{p{0.6\textwidth}|}{test case, проведение тестирований, тестирование api, функциональное тестирование, нагрузочное тестирование, диагностика, a/b testing, ручное тестирование, тестирование, модульное тестирование, регрессионное тестирование, a/b тесты, диагностика пк, a/b тестирование, регресcионное тестирование, functional testing, кроссбраузерное тестирование, тестовая документация, тест-кейсы, testing framework, тест-дизайн, a/b-тестирование} &
  0.09042 \\ \hline
\multicolumn{1}{|l|}{976} &
  \multicolumn{1}{l|}{интеграционное тестирование} &
  0.0 \\ \hline
\multicolumn{1}{|l|}{1057} &
  \multicolumn{1}{l|}{beta-тестирования} &
  0.0 \\ \hline
\multicolumn{1}{|l|}{818} &
  \multicolumn{1}{l|}{тестирование qa} &
  0.0 \\ \hline
\multicolumn{3}{|l|}{\textbf{Note - Compiled by the author}} \\ \hline
\end{tabular}%
\end{table}

\begin{table}[H]
\caption*{Table 3 - Cluster 33}
\centering
\begin{tabular}{|p{0.1\textwidth}lp{0.11\textwidth}|}
\hline
\multicolumn{1}{|p{0.1\textwidth}|}{\textbf{Cluster number}} &
  \multicolumn{1}{l|}{\textbf{Skills in the cluster}} &
  \textbf{Silhouette coefficient} \\ \hline
\multicolumn{1}{|l|}{33} &
  \multicolumn{1}{p{0.7\textwidth}|}{java, верстка, vue, лвс, ui, vuejs, veam, sap fi, osi, скд, с\#, релиз, jpa, lte, асутп, сапр, asana, kotlin, впр, pestel, ge/m, vlan, java ee, сопровождение по, снип, itil, otrs, presales, nat, онбординг, sono, siem, unix, java se, idef, trello, глонасс, rtos, mbedos, срм, iis, koin di, vue js, pascal, kafka для очередей, fastapi, vuetify, фронтенд, удаленка, абис, uix, jest, nestjs, nodejs, цод, vrrp, айдентика, aiohtpp, парсер, сбор трейсов, zbrush, спецпроекты, ar, lld, асу тп, стпо, ai, impa, ррл, vite, бэм, плк, геттеры, смр, olap, aris, erspan, cacti, xunit, gradle, prd, gke, maven, ремонт п, пайка, переустановка по, trc, bem, сметы, гис, эсф, perco, vr, по, опс, java/kotlin, xamarin, лендинг, vtiger, биот, эдо, эквайринг, предовос, пэк, ппм, ндв, пдс, сзз, palo alto, jvm, суиб, волс, talend, пресейл, presale, pam, estaff, актуарий, uart, serdes, отладка, saml, элеткрик, пк, екв, в2в., wcdma} &
  0.0063 \\ \hline
\multicolumn{3}{|l|}{\textbf{Note - Compiled by the author}} \\ \hline
\end{tabular}%
\end{table}

\begin{multicols}{2}
An analysis of the table for Cluster 33 reveals a large number of
diverse skills, ranging from programming (Java, Kotlin, Node.js) to
specialized technical and engineering areas (soldering, repair, software
reinstallation). The very low silhouette coefficient (0.0063) indicates
that this cluster is poorly separated from others, possibly due to its
excessive heterogeneity.

The remaining skills do not form clusters and have a silhouette
coefficient of zero. These isolated skills constitute approximately 19\%
of the total number of skills.

Analyzing the results, it can be stated that the distribution of
silhouette coefficients reflects the quality of the clustering.
Typically, the silhouette coefficient ranges from 1 to -1. In our case,
clusters with a high silhouette coefficient, ranging from 1 to 0.04,
exhibit acceptable quality upon inspection and can be used to create
skill communities within a knowledge graph. Clusters with a silhouette
coefficient between 0.03 and 0 are not suitable for community creation
within the graph, as they have very blurred boundaries and include
overly heterogeneous terms. Clusters with a zero silhouette coefficient
include unique skills that do not cluster with other skill formulations.
Clusters with a negative silhouette coefficient are of very poor quality
and may include highly heterogeneous data. However, in our selected
configuration, such clusters were not observed as a result of the
experiments.

When the silhouette coefficient threshold for each cluster is set above
0.03, these clusters will subsequently be used to identify skill
communities within job and skill knowledge graphs.

In analyzing clusters formed from skills in both Russian and English, it
is important to note that this approach allows for the consideration of
linguistic diversity, making the clustering process more adaptive and
accurate for multilingual data. This approach enables a better
understanding of data structure and provides a higher-quality analysis
of skills or qualifications.

When analyzing potential clustering errors, a key pattern can be
observed that may affect cluster quality, particularly in relation to
phrase length. Short phrases or abbreviations often carry less unique
information and may be erroneously grouped due to similarities in
spelling or pronunciation. For example, abbreviations such as SCCM and
SCTP might be clustered with Scrum, despite differences in their
functions and applications.

For short words and abbreviations, it was necessary to improve embedding
generation algorithms and conduct additional clustering. The additional
training of the multilingual Paraphrase-multilingual-mpnet-base-v2 model
used for generating embeddings based on the paraphrase data set "short
abbreviation-full form" partially solved the problem.

Let' s consider the ratio of individual skills and
erroneous clusters with a positive silhouette coefficient obtained
before and after training. The correctness of cluster formation was
evaluated by an expert.
\end{multicols}

\begin{table}[H]
    \centering
    \caption*{Table 4 - Comparison of erroneous clusters before and after training the embedding model}
    \begin{tabular}{|>{\centering\arraybackslash}p{0.12\textwidth}|>{\centering\arraybackslash}p{0.1\textwidth}|>{\centering\arraybackslash}p{0.2\textwidth}|>{\centering\arraybackslash}p{0.2\textwidth}|>{\centering\arraybackslash}p{0.2\textwidth}|}
        \hline
        \textbf{Embedding model} & \textbf{Silhouette coefficient} & \textbf{Number of clusters (including single terms)} & \textbf{Percentage of Single Terms from Total Skills (3047)} & \textbf{Percentage of erroneous clusters} \\ 
        \hline
        Before training & 0,27126 & 1121 & 19,17\% & 19,74\% \\ 
        \hline
        After training & 0,2851 & 1407 & 24\% & 13,97\% \\ 
        \hline
    \end{tabular}
\end{table}

\begin{multicols}{2}
Fine-tuning the model led to an increase in the number of clusters,
which may indicate more detailed segmentation of skills. The increase in
the average silhouette coefficient and the percentage of successful
clusters points to improved clustering quality after fine-tuning the
model. The percentage of erroneous clusters decreased, further
confirming the model' s improved performance. After
further training, there was a partial improvement in results, but for
better results it is necessary to create a separate dictionary of
abbreviations.

To address the potential for scalability of our approach beyond the IT
sector, we can expand its applicability to other professional domains,
such as finance, healthcare, and engineering. The methodology can be
adapted to these areas by incorporating domain-specific skills.
Potential adaptations include the use of specialized embedding models
trained on sector-relevant text corpora, which would enable more
accurate clustering of context-specific skills. For instance, in the
healthcare sector, medical terminologies and technical jargon could be
incorporated into the embedding space to improve the identification of
skill communities. Similarly, in the finance sector, the inclusion of
financial industry terms and competencies could enhance the clustering
process.

{\bfseries Conclusions.} This study explored the application of
agglomerative hierarchical clustering for analyzing skills extracted
from an online recruitment platform. The research encompassed a broad
range of linkage methods and distance metrics, allowing for the
assessment and comparison of the effectiveness of each approach in the
context of clustering semantically diverse data.

It was found that agglomerative clustering methods hold significant
potential for identifying structured groups of skills, which can enhance
the understanding of labor market trends and needs. The analysis of
clusters formed in different languages confirmed the universality and
adaptability of the proposed approach to multilingual data.

However, certain issues were also identified during the analysis, such
as overlapping clusters and low silhouette coefficient values in some
clustering configurations. These observations have indicated the need
for further refinement of data preprocessing techniques to improve the
quality of results. After further training of the embedding model on
paraphrases, a partial improvement in results was observed, however, a
separate dictionary of abbreviations will be created for the best
results.

The findings of this study can be utilized to develop more effective
data analysis tools, including the creation of educational programs and
skill development strategies tailored to the evolving conditions of the
labor market. The proposed methods and approaches may also find
application in other areas where analyzing large volumes of textual
information is required to identify hidden patterns and relationships.

In conclusion, despite certain challenges, the results achieved confirm
the value and effectiveness of hierarchical agglomerative clustering as
a tool for deep data analysis, opening new avenues for further research
and practical applications in the field of data analytics.

\emph{{\bfseries Financing.} This research is funded by the Science
Committee of the Ministry of Science and Higher Education of the
Republic of Kazakhstan (Grant No. AP22783030).}
\end{multicols}

\begin{center}
{\bfseries References}
\end{center}

\begin{references}
1. Fortunato, S. (2010). Community detection in graphs// Physics
Reports.- 2010.-Vol.486(3-5).-P. 75-174.
\href{https://doi.org/10.1016/j.physrep.2009.11.002}{DOI
10.1016/j.physrep.2009.11.002}

2. Oti, E., \& Olusola, M. (2024). Overview of agglomerative
hierarchical clustering methods //British Journal of Computer,
Networking and Information Technology.-2024.-Vol., 7(2).-P 14-23.
\href{https://doi.org/10.52589/BJCNIT-CV9POOGW}{DOI
10.52589/BJCNIT-CV9POOGW}

3.Tokuda, E. K., Comin, C. H., \& Costa, L. F. (2022). Revisiting
agglomerative clustering// Physica A: Statistical Mechanics and Its
Applications.- Vol.585, Article 126433. DOI
\href{https://doi.org/10.1016/j.physa.2021.126433}{10.1016/j.physa.2021.126433}


4. Sumengen, B. (2021). Scaling hierarchical agglomerative clustering to
billion-sized datasets. arXiv, 2021. DOI
\href{https://doi.org/10.48550/arXiv.2105.11653}{10.48550/arXiv.2105.11653}

5. Cena, A., \& Gagolewski, M. (2020). Genie+OWA: Robustifying
hierarchical clustering with OWA-based linkages// Information
Sciences.-2020.-Vol. 520.-P. 324-336.
\href{https://doi.org/10.1016/j.ins.2020.02.025}{DOI
10.1016/j.ins.2020.02.025}


6. Gagolewski, M., Bartoszuk, M., \& Cena, A. Are cluster validity
measures (in)valid? //Information Sciences.-2021.-Vol. 581.- P.
620-634. \href{https://doi.org/10.1016/j.ins.2021.10.004}{DOI
10.1016/j.ins.2021.10.004}

7. Söküt Açar, T., \& Öz, N. A. The determination of optimal cluster
number by silhouette index at clustering of the European Union member
countries and candidate Turkey by waste indicators// Politeknik
Dergisi.-2020.-Vol. 26(3). \href{https://doi.org/10.5505/pajes.2019.49932}{DOI 10.5505/pajes.2019.49932}

8. TabassumA., Patil R. R. A survey on text pre-processing \& feature
extraction techniques in natural language processing.//International
Research Journal of Engineering and Technology.-2020ю-Vol.7(6).-
P.4864-4867. \\\href{https://www.semanticscholar.org/paper/A-Survey-on-Text-Pre-Processing-\%26-Feature-in-Tabassum-Patil/f308488e996599115fe478c03b74a0b19b9a8f06}{https://www.semanticscholar.org}

9. Pugachev L., BurtsevM. (2021). Short text clustering with
transformers, ArXiv:21.02.00541v1

DOI
\href{http://dx.doi.org/10.28995/2075-7182-2021-20-571-577}{10.28995/2075-7182-2021-20-571-577}

10. GalliC., Donos N.,CalciolariE. Performance of 4 pre-trained sentence
transformer models in the semantic query of a systematic review
dataset on peri-implantitis//Information.- 2024.- Vol.15(2), Article
68. \\\href{https://doi.org/10.3390/info15020068}{DOI
10.3390/info15020068}

11. Ternikov A. A. (2022). Skill-based clustering algorithm for online job
advertisements// Izvestiya of Saratov University. Mathematics.
Mechanics. Informatics.-2022.- Vol.22(2).-P. 250-265.
\href{https://doi.org/10.18500/1816-9791-2022-22-2-250-265}{DOI
10.18500/1816-9791-2022-22-2-250-265}

12. Karthikeyan, B. A comparative study on K-means clustering and
agglomerative hierarchical clustering// Interna-tional Journal of
Emerging Trends in Engineering Researc.-2020.-Vol. 8(5).-P. 1600-1604.
\href{https://doi.org/10.30534/ijeter/2020/20852020}{DOI
\\10.30534/ijeter/2020/20852020}

13. Bafna, P., Pramod, D., \& Vaidya, A. (2016, March). Document
clustering: TF-IDF approach. In 2016 International Conference on
Electrical, Electronics, and Optimization Techniques (ICEEOT) (pp.
61-66). \\\href{https://doi.org/10.1109/ICEEOT.2016.7754750}{DOI
10.1109/ICEEOT.2016.7754750}

14. Srivastava, R., Hingmire, S., \& Palshikar, G. K. (2020). Clustering
skills for industrial learning. TCS Research, Tata Research Design \&
Development Centre, Hadapsar, Pune.
\href{https://www.cse.msu.edu/~wangzh65/AI4EDU/papers/15.pdf}{https://www.cse.msu.edu}

15. Biloshchytskyi, A., Shamgunova, . M. ., \& Biloshchytska , S. .
(2024). Exploration of the thematic clustering and collaboration
opportunities in Kazakhstani research//Scientific Journal of Astana IT
University.-2024.-Vol. 17(17).-P.106-121.
\href{https://doi.org/10.37943/17ALVR8114}{DOI 10.37943/17ALVR8114}

16. Ternikov, A. A. Skill-based clustering algorithm for online job
advertisements// Izvestiya of Saratov University. Mathematics.
Mechanics. Informatics,.-2022.- 22(2).-P. 250 - 265.
\href{https://doi.org/10.18500/1816-9791-2022-22-2-250-265}{DOI
10.18500/1816-9791-2022-22-2-250-265}

17. Dikov M.E., Shirobokova S.N. O variante formalizacii zadachi
izvlechenija kljuchevyh navykov i klasternogo analiza vakansij pri
realizacii kompleksnogo instrumentarij cifrovoj proforientacii.//
Inzhenernyj vestnik Dona.-2024.- № 3.- S.1-10.{[}in Russian{]}
\href{https://cyberleninka.ru/article/n/o-variante-formalizatsii-zadachi-izvlecheniya-klyuchevyh-navykov-i-klasternogo-analiza-vakansiy-pri-realizatsii-kompleksnogo}{https://cyberleninka.ru}
\end{references}

\begin{authorinfo}
\hspace{1em}\emph{{\bfseries Сведение об авторах}}

Рамазанова В. С.- магистр технических наук, Евразийский национальный
университет им. Л. Н. Гумилева, Астана, Казахстан, е-mail:
\href{mailto:ramazanovavs@gmail.com}{\nolinkurl{ramazanovavs@gmail.com}};

Самбетбаева М. А.- PhD, Евразийский национальный университет им. Л. Н.
Гумилева Астана, Казахстан,

е-mail:
\href{mailto:madina_jgtu@mail.ru}{\nolinkurl{madina\_jgtu@mail.ru}};

Тохметов А. Т. - доцент, Евразийский национальный университет им. Л.Н.
Гумилева, Астана, Казахстан, e-mail:\\
\href{mailto:attohmetov@mail.ru}{\nolinkurl{attohmetov@mail.ru}};

Ламашева Ж. Б. - PhD, Евразийский национальный университет им. Л. Н.
Гумилева, Астана, Казахстан,

е-mail:
\href{mailto:lamasheva_zhb@enu.kz}{\nolinkurl{lamasheva\_zhb@enu.kz}} ;

Серикбаева С. К. - PhD, Евразийский национальный университет им. Л. Н.
Гумилева, Астана, Казахстан,

е-mail: \href{mailto:inf_8585@mail.ru}{\nolinkurl{inf\_8585@mail.ru}}

\hspace{1em}\emph{{\bfseries Information about the authors}}

Ramazanova V. - master of technical sciences, L. N. Gumilyov Eurasian
National University, Astana, Kazakhstan, \\е-mail: ramazanovavs@gmail.com;

Sambetbayeva M. - PhD, L. N. Gumilyov Eurasian National University,
Astana, Kazakhstan, е-mail:
\href{mailto:madina_jgtu@mail.ru}{\nolinkurl{madina\_jgtu@mail.ru}};

Tokhmetov A. - associate professor, L.N. Gumilyov Eurasian National
University, Astana, Kazakhstan, е-mail:
\\\href{mailto:attohmetov@mail.ru}{\nolinkurl{attohmetov@mail.ru}};

Lamasheva Zh. - PhD, L.N. Gumilyov Eurasian National University, Astana,
Kazakhstan, е-mail:
\href{mailto:lamasheva_zhb@enu.kz}{\nolinkurl{lamasheva\_zhb@enu.kz}};

Serikbayeva S. - PhD, L.N. Gumilyov Eurasian National University,
Astana, Kazakhstan, е-mail:
\href{mailto:inf_8585@mail.ru}{\nolinkurl{inf\_8585@mail.ru}}
\end{authorinfo}
